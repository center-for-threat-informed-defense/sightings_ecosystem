{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234c5165-6ec6-40bd-a5db-82b4411ddf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Associative rule mining on a list of itemsets (groups)\n",
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from operator import itemgetter\n",
    "from typing import Any, Iterable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "class AssociativeRules:\n",
    "    def __init__(\n",
    "        self,\n",
    "        groups: Iterable[Any],\n",
    "        order=False,\n",
    "        threshold=None,\n",
    "        min_count=None,\n",
    "        rule_filter=\"chi_squared\",\n",
    "    ):\n",
    "        self.groups = groups\n",
    "        self.order = order\n",
    "        self.threshold = threshold\n",
    "        self.min_count = min_count\n",
    "        self.rule_filter = rule_filter\n",
    "        self.nsets = len(groups)\n",
    "        self.rules = {}\n",
    "        self.pair_counts = defaultdict(int)\n",
    "        self.item_counts = defaultdict(int)\n",
    "        self.mean_item_count = None\n",
    "        self.list_of_rules = []\n",
    "\n",
    "    def update_pair_counts(self, itemset):\n",
    "        \"\"\"\n",
    "        Updates the dictionary of pair counts for\n",
    "        all pairs of items in a given itemset.\n",
    "        \"\"\"\n",
    "        assert type(self.pair_counts) is defaultdict\n",
    "\n",
    "        # check each combination of 2 items from the itemset\n",
    "        for a, b in combinations(itemset, 2):\n",
    "            self.pair_counts[(a, b)] += 1\n",
    "            if self.order is False:\n",
    "                self.pair_counts[(b, a)] += 1  # if order DOES NOT matter\n",
    "\n",
    "    def update_item_counts(self, itemset):\n",
    "        \"\"\"\n",
    "        Updates the dictionary of item counts for\n",
    "        all items in a given itemset.\n",
    "        \"\"\"\n",
    "        for i in itemset:\n",
    "            self.item_counts[i] += 1\n",
    "\n",
    "    def filter_rules_by_conf(self):\n",
    "        \"\"\"\n",
    "        For a given combination of 2 items from an itemset, (item_a, item_b),\n",
    "        calculates conf, the confidence that (item_a => item_b).\n",
    "        If conf > threshold and a occurs more than min_count times,\n",
    "        add rule to the dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        for (a, b) in self.pair_counts.keys():\n",
    "            assert a in self.item_counts\n",
    "            conf = self.pair_counts[(a, b)] / self.item_counts[a]\n",
    "            has_reached_threshold = conf >= self.threshold\n",
    "            has_minimum_count = self.item_counts[a] >= self.min_count\n",
    "            if has_reached_threshold and has_minimum_count:\n",
    "                self.rules[(a, b)] = conf\n",
    "\n",
    "    def filter_rules_by_chi2(self, level):\n",
    "        \"\"\"\n",
    "        For a given combination of 2 items from an itemset, (item_a, item_b),\n",
    "        Calculates the X^2  test statistic for each pair of items.\n",
    "        If larger than the cutoff X^2 for 1dof and 99% default\n",
    "        significance level, reject independence assumption and add to rule list\n",
    "        Reference---- ICDM 2006: Advances in Data Mining. Applications in\n",
    "        Medicine, Web Mining, Marketing, Image and Signal Mining pp 202-216\n",
    "        \"\"\"\n",
    "        assert 1 >= level > 0\n",
    "\n",
    "        dof = 1  # 1 degree of freedom\n",
    "        for (a, b) in self.pair_counts.keys():\n",
    "            assert a in self.item_counts\n",
    "            assert b in self.item_counts\n",
    "            # calculate supports\n",
    "            s_a = self.item_counts[a] / self.nsets\n",
    "            s_b = self.item_counts[b] / self.nsets\n",
    "            s_ab = self.pair_counts[(a, b)] / self.nsets\n",
    "            # calculate chi^2\n",
    "            try:\n",
    "                tstat = self.nsets * (s_ab - s_a * s_b) ** 2 / (s_a * s_b * (1 - s_a) * (1 - s_b))\n",
    "                cdf = chi2.cdf(tstat, dof)\n",
    "                if cdf >= level and self.item_counts[a] >= self.min_count:\n",
    "                    self.rules[(a, b)] = cdf\n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                print(\"ZeroDivisionError\", a, b, s_a, s_b, s_ab)\n",
    "\n",
    "    def find_assoc_rules(self, level=0.99):\n",
    "        \"\"\"\n",
    "        Using update_pair_counts, update_item_counts and desired rule filter\n",
    "        (filter_rules_by_conf or filter_rules_by_chi2),\n",
    "        Rules are extracted from the inputted groups\n",
    "        If filtering by chi^2, can specify a confidence level\n",
    "        in the range (0,1). The default is 0.99.\n",
    "        \"\"\"\n",
    "\n",
    "        for itemset in self.groups:\n",
    "            self.update_pair_counts(itemset)\n",
    "            self.update_item_counts(itemset)\n",
    "\n",
    "        if len(self.item_counts) > 0:\n",
    "            self.mean_item_count = sum(self.item_counts.values()) / len(self.item_counts.values())\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"No items in groups. Ensure you have processed data via the pipeline prior to running analysis.\"\n",
    "            )\n",
    "\n",
    "        # if a value is not given for min_count use mean_item_count\n",
    "        if not self.min_count:\n",
    "            self.min_count = self.mean_item_count\n",
    "\n",
    "        if self.rule_filter == \"conf\":\n",
    "            # print('filtering by conf')\n",
    "            self.filter_rules_by_conf()\n",
    "        else:\n",
    "            # print('filtering by chi2 to significance level of ', level)\n",
    "            self.filter_rules_by_chi2(level)\n",
    "\n",
    "        ordered_rules = sorted(self.rules.items(), key=itemgetter(1), reverse=True)\n",
    "        # print(ordered_rules)\n",
    "        for (a, b), statistic_ab in ordered_rules:\n",
    "            self.list_of_rules.append([a, b, statistic_ab])\n",
    "\n",
    "    def gen_rule_str(self, a, b, val=None, val_fmt=\"{:.3f}\", sep=\" = \"):\n",
    "        text = \"{} => {}\".format(a, b)\n",
    "        if val:\n",
    "            text = self.rule_filter + \"(\" + text + \")\"\n",
    "            text += sep + val_fmt.format(val)\n",
    "        return text\n",
    "\n",
    "    def print_rules(self):\n",
    "        if type(self.rules) is dict or type(self.rules) is defaultdict:\n",
    "\n",
    "            ordered_rules = sorted(self.rules.items(), key=itemgetter(1), reverse=True)\n",
    "        else:  # Assume rules is iterable\n",
    "            ordered_rules = [((a, b), None) for a, b in self.rules]\n",
    "        for (a, b), statistic_ab in ordered_rules:\n",
    "            print(self.gen_rule_str(a, b, statistic_ab))\n",
    "\n",
    "    def draw_graph(self, method=\"nx\"):\n",
    "\n",
    "        df = pd.DataFrame(self.list_of_rules, columns=[\"source\", \"target\", \"conf\"])\n",
    "        G = nx.from_pandas_edgelist(\n",
    "            df,\n",
    "            source=\"source\",\n",
    "            target=\"target\",\n",
    "            edge_attr=\"conf\",\n",
    "            create_using=nx.DiGraph,\n",
    "        )\n",
    "        if method == \"nx\":\n",
    "            nx.draw_networkx(G)\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(\"rule_mining.png\")\n",
    "        if method == \"ipycytoscape\":  # for jupyter notebooks\n",
    "            import ipycytoscape\n",
    "\n",
    "            directed = ipycytoscape.CytoscapeWidget()\n",
    "            directed.graph.add_graph_from_networkx(G, directed=True)\n",
    "\n",
    "            directed.set_style(\n",
    "                [\n",
    "                    {\n",
    "                        \"selector\": \"node\",\n",
    "                        \"css\": {\n",
    "                            \"content\": \"data(id)\",\n",
    "                            \"text-valign\": \"center\",\n",
    "                            \"color\": \"white\",\n",
    "                            \"text-outline-width\": 2,\n",
    "                            \"text-outline-color\": \"blue\",\n",
    "                            \"text-wrap\": \"wrap\",\n",
    "                            \"text-max-width\": \"10px\",\n",
    "                            \"text-overflow-wrap\": \"whitespace\",\n",
    "                            \"background-color\": \"blue\",\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"selector\": \"edge\",\n",
    "                        \"css\": {\n",
    "                            \"mid-target-arrow-shape\": \"triangle\",\n",
    "                            \"mid-target-arrow-fill\": \"filled\",\n",
    "                            \"arrow-scale\": 2,\n",
    "                        },\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            directed.set_layout(name=\"cose\", nodeOverlap=40, idealEdgeLength=60)\n",
    "            return directed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8bbd1-fb62-4b1c-8100-ac1629cdf3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
